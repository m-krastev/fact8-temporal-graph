{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "[Errno 2] No such file or directory: '../new_dir/DATA/MOOC/edge_features.pt'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMOOC\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m edges \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/edges.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m edge_features \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msrc_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/edge_features.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ext_full = np.load(f\"./new_dir/DATA/{dataset}/int_train.npz\")\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# edges_repr = np.load.read_csv(f\"./new_dir/DATA/{dataset}/edges_repr.npy\", index_col=0)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# for i in ['indptr', 'indices', 'ts', 'eid']:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     print(ext_full[i].shape)\u001b[39;00m\n",
                        "File \u001b[0;32m~/fact8/.venv/lib/python3.11/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
                        "File \u001b[0;32m~/fact8/.venv/lib/python3.11/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
                        "File \u001b[0;32m~/fact8/.venv/lib/python3.11/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
                        "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../new_dir/DATA/MOOC/edge_features.pt'"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import torch\n",
                "\n",
                "src_dir = \"../new_dir/DATA\"\n",
                "tgt_dir = \"../tgnnexplainer/xgraph/models/ext/tgat/processed\"\n",
                "dataset = \"MOOC\"\n",
                "\n",
                "edges = pd.read_csv(f\"{src_dir}/{dataset}/edges.csv\", index_col=0)\n",
                "# edge_features = torch.load(f\"{src_dir}/{dataset}/edge_features.pt\")\n",
                "\n",
                "# ext_full = np.load(f\"./new_dir/DATA/{dataset}/int_train.npz\")\n",
                "\n",
                "# for i in ['indptr', 'indices', 'ts', 'eid']:\n",
                "#     print(ext_full[i].shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[ 0.49277036, -0.69036051,  1.34358778,  1.54337125],\n",
                            "       [-0.47879322, -1.11126717, -0.46390797,  1.23420109],\n",
                            "       [ 0.55225519, -0.70049968,  1.12268004, -2.12257938],\n",
                            "       ...,\n",
                            "       [ 0.02733296,  0.98931901,  0.19821423, -1.06424055],\n",
                            "       [ 0.38313002,  1.13750433, -1.96857973,  0.77038375],\n",
                            "       [-0.12718611, -2.66271972,  0.30175013, -0.70065818]])"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "def prepare_data_mooc(df: pd.DataFrame):\n",
                "    df = df.rename(columns={\"src\": \"u\", \"dst\": \"i\", \"time\": \"ts\", \"ext_roll\":\"label\"})\n",
                "    df[\"label\"] -= 1\n",
                "    \n",
                "    df['u'] = df['u'].astype(int)\n",
                "    df['i'] = df['i'].astype(int)\n",
                "\n",
                "    df.insert(len(df.columns), \"idx\", range(df.shape[0]))\n",
                "    df.insert(len(df.columns), \"e_idx\", range(df.shape[0]))\n",
                "\n",
                "    df = df.drop(columns=\"int_roll\")\n",
                "    return df\n",
                "\n",
                "\n",
                "ml_mooc = prepare_data_mooc(edges)\n",
                "ml_mooc.to_csv( f\"{tgt_dir}/ml_{dataset}.csv\", index=False)\n",
                "\n",
                "\n",
                "# For random generation\n",
                "# ml_features = np.random.randn(len(ml_mooc), 4)\n",
                "# np.save(\n",
                "#     f\"{tgt_dir}/ml_{dataset}_node.npy\",\n",
                "#     ml_features,\n",
                "# )\n",
                "\n",
                "# ml_features = np.random.randn(len(ml_mooc), 4)\n",
                "# np.save(\n",
                "#     f\"{tgt_dir}/ml_{dataset}.npy\", ml_features\n",
                "# )\n",
                "# ml_features\n",
                "\n",
                "np.save(\n",
                "    f\"{tgt_dir}/ml_{dataset}.npy\", edge_features.numpy()\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "mlkit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}